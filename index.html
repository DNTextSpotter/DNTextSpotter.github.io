<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta name="description" content="ShareGPT4Video: Improving Video Understanding and Generation with Better Captions">
    <meta name="keywords" content="ShareGPT4Video">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>ShareGPT4Video</title>
  
    <link rel="icon" href="images/logo.png">
  
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro">
    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="stylesheet" href="./static/css/leaderboard.css">
  
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script type="text/javascript" src="./static/js/sort-table.js" defer></script>
    <script src="./static/js/fontawesome.all.min.js" defer></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/explorer-index.js"></script>
    <script src="./static/js/question_card.js"></script>
    <script src="./static/js/leaderboard_testmini.js"></script>  
  </head>

  <body>

    <nav class="navbar" role="navigation" aria-label="main navigation">
      <div class="navbar-brand">
        <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
        </a>
      </div>
      <div class="navbar-menu">
        <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
          <div class="navbar-item has-dropdown is-hoverable">
            <a class="navbar-link">
              More Research
            </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://mmstar-benchmark.github.io/">
              <b><img src="images/mmstar.png" style="width:2.0em;vertical-align: middle" alt="Logo"/>MMStar</b>
            </a>
            <a class="navbar-item" href="https://sharegpt4v.github.io/">
              <b><img src="images/sharegpt4v.png" style="width:2.0em;vertical-align: middle" alt="Logo"/>ShareGPT4V</b>
            </a>
          </div>
        </div>
      </div>
    </nav>
    
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-2 publication-title"><img id="logo" width="5%" src="images/logo.png"> ShareGPT4Video: Improving Video Understanding and Generation with Better Captions</h1>
              <div class="is-size-5 publication-authors">
                <br>
                <span class="author-block">
                  <a href="https://lin-chen.site/" style="font-weight:normal;">Lin Chen<b><sup>* &sect;1,2</sup></b></a>,
                </span>
                <span class="author-block">
                  <a href="https://github.com/Wiselnn570/" style="font-weight:normal;">Xilin Wei<b><sup>* &sect;2</sup></b></a>,
                </span>
                <span class="author-block">
                  <a href="https://li-jinsong.github.io/" style="font-weight:normal;">Jinsong Li<b><sup>* &sect;2</sup></b></a>,
                </span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=FscToE0AAAAJ&hl=en" style="font-weight:normal;">Xiaoyi Dong<sup>2</sup></a>,
                </span>
                <span class="author-block">
                  <a href="https://panzhang0212.github.io/" style="font-weight:normal;">Pan Zhang<sup>2</sup></a>,
                </span>
                <span class="author-block">
                  <a href="https://yuhangzang.github.io/" style="font-weight:normal;">Yuhang Zang<sup>2</sup></a>,
                </span>
                <span class="author-block">
                  <a href="https://lovesnowbest.site/" style="font-weight:normal;">Zehui Chen<sup>1,2</sup></a>,
                </span>
                <span class="author-block">
                  <a href="https://kennymckormick.github.io/" style="font-weight:normal;">Haodong Duan<sup>2</sup></a>,
                </span>
                <span class="author-block">
                  <a href="https://scholar.google.com.hk/citations?user=GCOVDKoAAAAJ&hl=en" style="font-weight:normal;">Bin Lin<sup>3</sup></a>,
                </span>
                <span class="author-block">
                  <a href="" style="font-weight:normal;">Zhenyu Tang<sup>3</sup></a>,
                </span>
                <span class="author-block">
                  <a href="https://yuanli2333.github.io/" style="font-weight:normal;">Li Yuan<sup>3</sup></a>,
                </span>
                <span class="author-block">
                  <a href="http://dahua.site/" style="font-weight:normal;">Dahua Lin<b><sup>2</sup></b></a>,
                </span>
                <span class="author-block">
                  <a href="https://scholar.google.co.uk/citations?user=r6CvuOUAAAAJ&hl=en" style="font-weight:normal;">Feng Zhao<b><sup>&dagger;1</sup></b></a>,
                </span>
                <span class="author-block">
                  <a href="https://myownskyw7.github.io/" style="font-weight:normal;">Jiaqi Wang<b><sup>&dagger;2</sup></b></a>
                </span>
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block"><b style="color:#f68946; font-weight:normal">&#x25B6 </b> <sup>1</sup> University of Science and Technology of China</b></span>
                <span class="author-block"><b style="color:#008AD7; font-weight:normal">&#x25B6 </b> <sup>2 </sup> Shanghai AI Laboratory</span>
                <span class="author-block"><b style="color:#f68946; font-weight:normal">&#x25B6 </b> <sup>3 </sup> Peking University</span>
              </div>
              
              <div class="is-size-6 publication-authors">
                <br>
                <span class="author-block"><b>*</b> Equal contribution.</span>
                <span class="author-block"><b>&dagger;</b> Corresponding authors.</span>
              </div>
              
              <div class="is-size-6 publication-authors">
                <span class="author-block"><b><sup>&sect;</sup></b> Work done during an internship in Shanghai AI Laboratory.</span>
              </div>
              <div class="column has-text-centered">
                <div class="publication-links">
                  <span class="link-block">
                    <a href="" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arXiv</span>
                    </a>
                  </span>
                  <span class="link-block">
                    <a href="https://github.com/InternLM/InternLM-XComposer/tree/main/projects/ShareGPT4Video" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>
                  <span class="link-block">
                    <a href="" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <p style="font-size:18px">🤗</p>
                      </span>
                      <span>Dataset</span>
                    </a>
                  </span>
                  <span class="link-block">
                    <a href="" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <p style="font-size:18px">🤗</p>
                      </span>
                      <span>ShareCaptioner-Video</span>
                    </a>
                  </span>
                  <br>
                  <span class="link-block">
                    <a href="" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                          <p style="font-size:18px">🎬</p>
                      </span>
                      <span>ShareCaptioner-Video Demo</span>
                    </a>
                  </span>
                  <span class="link-block">
                    <a href="" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                          <p style="font-size:18px">🎬</p>
                      </span>
                      <span>ShareGPT4Video-8B Demo</span>
                    </a>
                  </span>
                </div>
                <font size="3">
                  <br>🚀 <b>A large-scale highly descriptive</b> video-text dataset, <b>40K</b> GPT4-Vision-generated video captions, around <b>400K</b> implicit video split captions
                  <br>🚀 <b>A general video captioner for various video durations, resolutions, aspect ratios</b>, approaching GPT4-Vision's caption capability, featuring two inference mode targeted for quality and efficiency, separately.
                  <br>🚀 A series of superior large multi-modal models <b>ShareGPT4Video-8B</b>, <b>ShareGPT4Video-34B</b>, lasting <b>1 hour</b> and <b>5 hours</b> on 32xA100 GPUs of training respectively.
                  <br>🚀 Improving <b>Text-to-Video performance</b> with high-quality video captions generate by our ShareCaptioner-Video
                </font>
                <br>
                <font size="6">
                  <br><b>NEWS</b>
                </font>
                <font size="5">
                  <br>🎉 <b style="color:#E68E34">[2024.05.08]</b> <b>Project Page</b> and <b>ShareGPT4Video Dataset</b> are released!</b>
                </font>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="hero is-light is-small" id="Video">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <br>
          <div class="publication-video">
            <h2 class="title is-3">Video</h2>
            <iframe src="https://www.youtube.com/embed/AQ7j3aegeeI?rel=0&amp;showinfo=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </section>


    <section class="section" id="Abstract">
      <div class="container" style="margin-bottom: 2vh;">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                Captions corresponding to video content provide a solid foundation for large video-language models (LVLMs) to comprehend real-world scenarios and for text-to-video models (T2VMs) to create vivid scenes from human descriptions.
                However, the lack of high-quality video-caption data poses a significant challenge, as brief captions cannot fully correspond with complex video content.
                To this end, we establish a high-quality video-caption dataset, ShareGPT4Video.
                Specifically, we select 40K diverse videos from multiple sources, including movies, ego-centric applications, landscapes, auto-driving scenarios, natural life, etc. We then introduce a semantic-aware key-frame extraction mechanism, a differential sliding-window captioning strategy, and a hierarchical prompt design to harness GPT4V for automatically and efficiently generating high-quality captions for videos of any duration. The resulting captions encompass rich world knowledge, object attributes, camera movements, and crucially, detailed and precise temporal descriptions of events. 
                With these efforts, our dataset allows users to flexibly compose captions for any video clip utilizing the provided key-frame captions and timestamps, creating a total of 400K video-caption pairs.
                Moreover, we develop ShareCaptioner-Video, a superior captioner capable of efficiently generating high-quality captions for videos with a wide range of resolution, aspect ratio, and duration.
                Through comprehensive experiments, we demonstrate the value of our proposed dataset and captioner in video understanding and generation tasks. We hope this project can serve as a pivotal resource for advancing both the LVLMs and T2VMs community.
              </p>
            </div>
          </div>
        </div>
      </div>

    </section>
    
    
    <section class="hero is-light is-small" id="Dataset Title">
      <div class="hero-body has-text-centered">
      <h1 class="title is-2">
        <img src="images/logo.png" style="width:4%;vertical-align: middle" alt="Logo"/>
        <span style="vertical-align: middle">ShareGPT4Video Dataset</span>
      </h1>
      </div>
    </section>
    <section class="section" id="Dataset">
      <div class="container">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <div class="content has-text-justified">
              <p><b>
                Dataset Statics
                </b>
                <centering>
                  <style>
                    table.GeneratedTable {
                      width: 100%;
                      background-color: #ffffff;
                      border-collapse: collapse;
                      border-width: 2px;
                      border-color: #c1c4c5;
                      border-style: solid;
                      color: #000000;
                    }
                    
                    table.GeneratedTable td, table.GeneratedTable th {
                      border-width: 2px;
                      border-color: #9b9d9e;
                      border-style: solid;
                      padding: 3px;
                    }
                    
                    table.GeneratedTable thead {
                      background-color: #6691ee;
                    }
                  </style>
                  <div class="column is-six-fifths" width="80%">
                  <table class="GeneratedTable">
                    <thead>
                      <tr>
                        <th>Data Source</th>
                        <th>Samples</th>
                        <th>Total Time(hours)</th>
                        <th>Avg. Time(sec)</th>
                        <th>Avg. Length(#word)</th>
                      </tr>
                    </thead>
                    <tbody>
                      <tr>
                        <td>Panda-70M</td>
                        <td>27092</td>
                        <td>204.4</td>
                        <td>27.2</td>
                        <td>291.2</td>
                      </tr>
                      <tr>
                        <td>Pexels</td>
                        <td>8487</td>
                        <td>52.2</td>
                        <td>22.1</td>
                        <td>254.9</td>
                      </tr>
                      <tr>
                        <td>Pixabay</td>
                        <td>2725</td>
                        <td>20.3</td>
                        <td>26.9</td>
                        <td>209.3</td>
                      </tr>
                      <tr>
                        <td>BDD100K</td>
                        <td>608</td>
                        <td>6.6</td>
                        <td>39.0</td>
                        <td>371.3</td>
                      </tr>
                      <tr>
                        <td>Mixkit</td>
                        <td>745</td>
                        <td>3.6</td>
                        <td>17.5</td>
                        <td>213.9</td>
                      </tr>
                      <tr>
                        <td>Ego4D</td>
                        <td>521</td>
                        <td>3.9</td>
                        <td>27.1</td>
                        <td>298.9</td>
                      </tr>
                      <tr bgcolor="#a4cff4">
                        <td>Total</td>
                        <td>40178</td>
                        <td>291</td>
                        <td>26.6</td>
                        <td>273.3</td>
                      </tr>
                    </tbody>
                  </table>
                  <p style="font-family:Times New Roman">
                    <font size=4>
                    <b>Comprehensive Video Caption Dataset:</b> High-Resolution, Diverse Scenarios from YouTube(Panda-70M), User-Uploaded Sites(Pexels, Pixabay, Mixkit), Ego4D, and BDD100K, which covers a broad spectrum of content including wildlife, cooking, sports, news, TV shows, gaming, 3D rendering, scenery, ego-centric human activities and auto-driving scenarios, tailored for comprehensive <b>video understanding</b> and <b>generation</b> needs.
                    </font>
                  </p> 
                </centering>
                <b>Pipeline</b>
                <centering>
                  <div style="text-align: center;">
                    <img id="teaser" width="100%" src="images/pipeline.png">
                    <p style="font-family:Times New Roman">
                      <font size=4>
                        <b>(a) ShareGPT4Video Dataset Pipeline</b>
                        <b>(b) Example of Generated Video Caption</b>
                      </font>
                    </p>
                  </div>
                </centering>
                <b>Text-to-Video Cases</b>
                <div id="results-carousel" class="carousel results-carousel">
                  <div class="box m-5">
                    <div class="content has-text-centered">
                      <h3 class="title is-4">Case 1</h3>
                      <video width="520" height="360" controls>
                        <source src="videos/8.mp4" type="video/mp4">
                      </video>
                      <div class="content has-text-justified">The camera rotates around a large stack of vintage televisions all showing different programs-1950s sci-fi movies, horror movies, news, static, a 1970s sitcom, etc, set inside a large New York museum gallery.</div>
                    </div>
                  </div>
                  <div class="box m-5">
                    <div class="content has-text-centered">
                      <h3 class="title is-4">Case 2</h3>
                      <video width="520" height="360" controls>
                        <source src="videos/9.mp4" type="video/mp4">
                      </video>
                      <div class="content has-text-justified">A drone camera circles around a beautiful historic church built on a rocky outcropping along the Amalfi Coast, the view showcases historic and magnificent architectural details and tiered pathways and patios, waves are seen crashing against the rocks below as the view overlooks the horizon of the coastal waters and hilly landscapes of the Amalfi Coast ltaly, several distant people are seen walking and enjoying vistas on patios of the dramatic ocean views, the warm glow of the afternoon sun creates a magical and romantic feeling to the scene, the view is stunning captured with beautiful photography.</div>
                    </div>
                  </div>
                  <div class="box m-5">
                    <div class="content has-text-centered">
                      <h3 class="title is-4">Case 3</h3>
                      <video width="520" height="360" controls>
                        <source src="videos/15.mp4" type="video/mp4">
                      </video>
                      <div class="content has-text-justified">A single drop of liquid metal falls from a floating orb, landing on a mirror-like surface and creating ripples that form intricate patterns. The shot zooms in on the mesmerizing effect, highlighting the fluid's reflective and transformative properties. High Resolution.</div>
                    </div>
                  </div>
                  <div class="box m-5">
                    <div class="content has-text-centered">
                      <h3 class="title is-4">Case 4</h3>
                      <video width="520" height="360" controls>
                        <source src="videos/12.mp4" type="video/mp4">
                      </video>
                      <div class="content has-text-justified">An aerial shot of a lighthouse standing tall on a rocky cliff, its beacon cutting through the early dawn, waves crash against the rocks below.</div>
                    </div>
                  </div>
                </div>
            </div> 
          </div>
        </div>
      </div>
    </section>
    
    <!--
    <section class="hero is-light is-small" id="Captioner Title">
      <div class="hero-body has-text-centered">
      <h1 class="title is-2">
        <img src="images/captioner.png" style="width:4%;vertical-align: middle" alt="Logo"/>
        <span style="vertical-align: middle">ShareCaptioner-Video</span>
      </h1>
      </div>
    </section>
    <section class="section" id="Captioner">
      <div class="container">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <div class="content has-text-justified">
              <p><b>
                介绍 & 2种原理图
                <centering>
                  <div style="text-align: center;">
                    <img id="teaser" width="90%" src="images/xxx.png">     
                  </div>
                </centering>
                <br>
                caption对比表格
                <centering>
                  <div style="text-align: center;">
                    <img id="teaser" width="60%" src="images/xxx.png">     
                  </div>
                </centering>
              </b></p>
            </div> 
          </div>
        </div>
      </div>
    </section>
    
    
    <section class="hero is-light is-small" id="Results Title">
      <div class="hero-body has-text-centered">
      <h1 class="title is-2">
        <span style="vertical-align: middle">📊 Results</span>
      </h1>
      </div>
    </section>
    <section class="section" id="Results">
      <div class="container">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <div class="content has-text-justified">
              <p><b>
                ShareGPT4Video-7B
                <centering>
                  <div style="text-align: center;">
                    <img id="teaser" width="90%" src="images/xxx.png">     
                  </div>
                </centering>
                <br>
                Generation
                <centering>
                  <div style="text-align: center;">
                    <img id="teaser" width="60%" src="images/xxx.png">     
                  </div>
                </centering>
              </b></p>
            </div> 
          </div>
        </div>
      </div>
    </section>
   
    
    
    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <h2 class="title is-3 has-text-centered">📃 BibTeX</h2>
        <pre><code>
          @article{
          }
        </code></pre>
        <br>
      </div>
    </section>
     --->
    
    <footer class="footer">
      <div class="content has-text-centered">
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website template is adapted from <a href="https://sharegpt4v.github.io/">ShareGPT4V</a>, <a href="https://mmstar-benchmark.github.io/">MMStar</a> and <a href="https://nerfies.github.io/">Nerfies</a>, licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>
            </p>
          </div>
        </div>
      </div>
    </footer>
    
    </body>
    
    
    </html>
    